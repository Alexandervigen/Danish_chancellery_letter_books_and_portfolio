---
title: "Untitled"
author: "Alexander V. Christiansen"
date: "2025-05-12"
output: html_document
---
Generally, the following code has been inspired by Max Odsbjergs St. Croix newspaper project, which operates with the same fundamental principles of assigning a tf-idf value to each term in the corpus. The project has been linked in the accompanying metadata file in github. 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Activating libraries:
```{r}
library(tidyverse)
library(tidytext)
library(ggwordcloud)
```

A dataframe is created from the csv:
```{r}
brevbøger_df <- read_csv("data/merged_brevbøger_1551-1660.csv")
```
(Strictly speaking, the creation of the csv was not necessary for running this code alone, but it makes reproducibility easier, as the csv-file is easily transferable. The below piece of code was, as an extension of this principle made for the purpose of reproducibility)

A new data frame is created, with the terms/words being split up into singular data points: 
```{r}
brevbøger_df %>% 
  unnest_tokens(word, Content) -> brevbøger_unnested
```

The words are counted: 
```{r}
brevbøger_unnested %>% 
  count(word, Year, sort = TRUE)
```

Total number of words for each year is found, and a new data frame is created: 
```{r}
brevbøger_unnested %>% 
  count(word, Year) %>% 
  group_by(Year) %>% 
  summarise(total = sum(n)) -> total_words
```

A data frame is created, in which 4 variables are given; year, word, number of that word and total words:
```{r}
brevbøger_unnested %>% 
  count(word,Year, sort = TRUE) %>% 
  left_join(total_words, by = "Year") -> brevbøger_count
```

A new data frame is created where term frequency, inverse document frequency and tf-idf are new variables:
```{r}
brevbøger_count %>% 
  bind_tf_idf(word, Year, n) -> brevbøger_tf_idf
```

THe terms are arranged in descending order by tf-idf:
```{r}
brevbøger_tf_idf %>% 
  arrange(desc(tf_idf))
```

Using regex, all strictly numerical terms are filtered out, and a simple stopword list is created:
```{r}
custom_stopwords <- c("på", "miss", "sj", "rex", "subscr")

brevbøger_tf_idf_nnp <- brevbøger_tf_idf %>%
  filter(!grepl("^\\d+$", word) & !word %in% custom_stopwords)
```
Part of the above code has been created with the aid of ChatGPT

Terms are arranged in descending order in this data frame as well:
```{r}
brevbøger_tf_idf_nnp %>% 
  arrange(desc(tf_idf))
```

A decade range is defined, and a wordcloud is created for this decade range with the n(in this case set to 10) words with the highest tf-idf for each year is showcased, with the highest ones being violet and large and lowest being blue and smaller. 
```{r}
start_year <- 1609
end_year <- 1622

brevbøger_tf_idf_nnp %>%
  filter(Year >= start_year, Year <= end_year) %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  group_by(Year) %>%
  slice_max(order_by = tf_idf, n = 10) %>%  
  ungroup() %>%
  ggplot(aes(label = word, size = tf_idf, color = tf_idf)) +
  geom_text_wordcloud_area() +
  scale_size_area(max_size = 12) +
  theme_minimal() +
  facet_wrap(~Year, ncol = 4, scales = "free") +
  scale_color_gradient(low = "blue", high = "violet") +
  labs(
    title = paste0("Most prominent words each year (", start_year, "–", end_year, ")"),
    subtitle = "Importance determined by term frequency (tf) - inversed document frequency (idf)",
    caption = "Kancelliets brevbøger"
  )
```
Part of the above code has been sourced from Max Odsbjergs educational exercise about the St. Croix newspapers, but has subsequently been altered. 


A nearly identical piece of code as the above, with the difference being that a bar plot is created using the code below instead. 
```{r}
start_year <- 1657
end_year <- 1657

brevbøger_tf_idf_nnp %>%
  filter(Year >= start_year, Year <= end_year) %>%
  arrange(desc(tf_idf)) %>%
  group_by(Year) %>%
  slice_max(order_by = tf_idf, n = 17) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, tf_idf, Year)) %>%  
  ggplot(aes(x = word, y = tf_idf, fill = tf_idf)) +
  geom_col(show.legend = FALSE) +
  scale_fill_gradient(low = "blue", high = "violet") +
  facet_wrap(~Year, scales = "free_y", ncol = 4) +
  coord_flip() +  
  scale_x_reordered() + 
  theme_minimal() +
  labs(
    title = paste0("Most prominent words each year (", start_year, "–", end_year, ")"),
    subtitle = "Importance determined by term frequency (tf) - inversed document frequency (idf)",
    x = NULL,
    y = "tf-idf",
    caption = "Kancelliets brevbøger"
  )
```
Part of the above code has been created using ChatGPT 
